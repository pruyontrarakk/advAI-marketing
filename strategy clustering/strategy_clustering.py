# -*- coding: utf-8 -*-
"""strategy_clustering.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bP-L5fE9eInxWQyl0OtcWZNyoAn_ITMk

# Load Dataset&preprocessing
"""

#load dataset from processed keywords
import pandas as pd

ads = pd.read_csv("collected_ads_enriched.csv")
nlp = pd.read_csv("image_text_analysis.csv")
nlp = nlp.drop(columns=["ocr_text"], errors="ignore")

#organize &cleaning
df = ads.merge(nlp, on="ad_id", how="inner")
df = df[df["ocr_word_count"] > 5]
df = df[df["ocr_confidence_avg"] > 50]
df = df[df["top_keywords"].notna()]
print(len(df))

df = df.reset_index(drop=True)
print(df.columns)

df["ocr_text"] = df["ocr_text"].str.replace(r"\b(www|com|http)\b", "", regex=True)
df["ocr_text"] = df["ocr_text"].str.replace(r"\d+", "", regex=True)

#transform them into vectors that computer can understand
fvectorizer = TfidfVectorizer(
    max_features=100,
    stop_words="english",
    min_df=5
)

numeric_features = df[[
    "sentiment_polarity",
    "sentiment_subjectivity"
]].fillna(0).values

print("Numeric rows:", numeric_features.shape[0])

import numpy as np

X = np.hstack((tfidf_matrix.toarray(), numeric_features)) #X is the clustering input
print(X.shape)

from sklearn.decomposition import TruncatedSVD

svd = TruncatedSVD(n_components=50, random_state=42)
X_reduced = svd.fit_transform(tfidf_matrix)

X = np.hstack((X_reduced, numeric_features))

"""# NON-supervised clustering(choose either one)"""

#for demo, something quick&simple:kmeans clustering
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=4, random_state=42)
df["cluster"] = kmeans.fit_predict(X)

#something deeper & avoid human interference when choosing k
pip install hdbscan

import hdbscan

clusterer = hdbscan.HDBSCAN(min_cluster_size=10)
df["cluster"] = clusterer.fit_predict(X)

"""# Cluster Interpretation"""

for c in df["cluster"].unique():
    print("Cluster", c)
    print(df[df["cluster"] == c]["top_keywords"].head(10))
    print("\n")

#are the clusters messy?
from sklearn.metrics import silhouette_score
score = silhouette_score(X, df["cluster"])
print("Silhouette score:", score)

"""note: After cleaning OCR noise, clustering revealed four  groups. While separation is not good enough (silhouette ~0.10), we can see some patterns including food/lifestyle, public health, brand-centric product ads, and functional promotional messaging."""

#MAPPING manually label, can edit
cluster_labels = {
    0: "Food & Lifestyle-Oriented Messaging",
    1: "Brand-Centric Product Messaging",
    2: "Public Health Messaging",
    3: "Functional Promotion Messaging"
}

df["strategy"] = df["cluster"].map(cluster_labels)

"""# Results"""

df.to_csv("ads_with_strategies.csv", index=False)